{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khajum/ai-playground/blob/main/rag/rag-application-101/pdf_loader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG Pipelines - Data Ingestion to Verctor DB Pipeline"
      ],
      "metadata": {
        "id": "8kr7TTwnDbCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install pypdf if not already installed\n",
        "!pip install langchain\n",
        "!pip install langchain-core\n",
        "!pip install langchain-community\n",
        "!pip install pypdf\n",
        "!pip install pymupdf"
      ],
      "metadata": {
        "id": "f_ra-ZZKDkh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
        "#from langchain.text_splitter import RecursiveCharacterTextSplitter\n"
      ],
      "metadata": {
        "id": "qu69PJ1gFvQu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Read all the PDFs inside directory './data/pdf/'\n",
        "def process_all_pdfs(pdf_directory):\n",
        "  # Process all the pdf files inside the directory\n",
        "  all_documents = []\n",
        "  pdf_dir = Path(pdf_directory)\n",
        "\n",
        "  # Find all the pdf files recursively\n",
        "  pdf_files = list(pdf_dir.glob('**/*.pdf'))\n",
        "\n",
        "  # print all the pdf files found in the directory\n",
        "  print(f\"Found {len(list(pdf_files))} pdf files in {pdf_directory}\")\n",
        "\n",
        "  for pdf_file in pdf_files:\n",
        "    print(f\"\\nProcessing: {pdf_file.name}\")\n",
        "    try:\n",
        "      loader = PyPDFLoader(str(pdf_file))\n",
        "      documents = loader.load()\n",
        "\n",
        "      # Add source information to metadata\n",
        "      for doc in documents:\n",
        "        doc.metadata['source_file'] = str(pdf_file.name)\n",
        "        doc.metadata['file_type'] = \"pdf\"\n",
        "\n",
        "      all_documents.extend(documents)\n",
        "      print(f\" Processed {pdf_file.name} with {len(documents)} pages\")\n",
        "    except Exception as e:\n",
        "      print(f\" Error processing {pdf_file.name}: {e}\")\n",
        "\n",
        "  print(f\" Total documents processed: {len(all_documents)}\")\n",
        "  return all_documents\n",
        "\n",
        "# Process all the PDFs in the data directory\n",
        "# Call the corrected function\n",
        "all_pdf_document = process_all_pdfs(\"./data\")\n",
        "print(f\"Successfully processed and collected {len(all_pdf_document)} documents.\")\n"
      ],
      "metadata": {
        "id": "SMiRQbPtGg6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-text-splitters"
      ],
      "metadata": {
        "id": "5xShnjMWSw7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "def split_document(documents, chunk_size=1000, chunk_overlap=200):\n",
        "  # split the documents into smaller chucks for better RAG performance\n",
        "  text_splitter = RecursiveCharacterTextSplitter(\n",
        "      chunk_size, chunk_overlap,\n",
        "      length_function=len,\n",
        "      separators = [\"\\n\", \"\\n\\n\", \" \", \"\"])\n",
        "  splits = text_splitter.split_documents(documents)\n",
        "  return splits"
      ],
      "metadata": {
        "id": "2fwylAeARpiY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
